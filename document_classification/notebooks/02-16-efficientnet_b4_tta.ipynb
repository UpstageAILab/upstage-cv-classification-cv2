{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms, utils, datasets, models\n",
    "from torch.nn.modules.loss import BCEWithLogitsLoss\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from time import time\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import wandb\n",
    "\n",
    "from augraphy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_path = 'data/dataset_50000/final_df.csv'\n",
    "submission_path = 'data/sample_submission.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드를 고정합니다.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, album_transform=None, augraphy_transform=None):\n",
    "        self.df = pd.read_csv(csv).values\n",
    "        self.path = path \n",
    "        self.album_transform = album_transform\n",
    "        self.augraphy_transform = augraphy_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        name, _, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        \n",
    "        if self.augraphy_transform:\n",
    "            img = self.augraphy_transform(img)\n",
    "\n",
    "        if self.album_transform:\n",
    "            img = self.album_transform(image=img)['image']\n",
    "        \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset1(Dataset):\n",
    "    def __init__(self, csv, path, album_transform=None, augraphy_transform=None):\n",
    "        self.df = pd.read_csv(csv).values\n",
    "        self.path = path \n",
    "        self.album_transform = album_transform\n",
    "        self.augraphy_transform = augraphy_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        \n",
    "        if self.augraphy_transform:\n",
    "            img = self.augraphy_transform(img)\n",
    "\n",
    "        if self.album_transform:\n",
    "            img = self.album_transform(image=img)['image']\n",
    "        \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, dataloader, dataset, device, criterion, optimizer, epoch, num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    tbar = tqdm(dataloader)\n",
    "    for images, labels in tbar:\n",
    "        images = images.type(torch.cuda.FloatTensor)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(outputs.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "        tbar.set_description(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss : {loss.item():.4f}\")\n",
    "\n",
    "    train_loss = train_loss / (len(dataloader))\n",
    "    train_acc = accuracy_score(preds_list, targets_list)\n",
    "    train_f1 = f1_score(preds_list, targets_list, average='macro')\n",
    "\n",
    "    metrics = {\n",
    "        'train_loss' : train_loss,\n",
    "        'train_acc' : train_acc,\n",
    "        'train_f1' : train_f1\n",
    "    }\n",
    "\n",
    "    return model, metrics\n",
    "\n",
    "def evaluation(model, dataloader, dataset, device, criterion, epoch, num_epochs):\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tbar = tqdm(dataloader)\n",
    "        for images, labels in tbar:\n",
    "            images = images.type(torch.cuda.FloatTensor)\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "            preds_list.extend(outputs.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "            tbar.set_description(f\"Epcoh [{epoch+1}/{num_epochs}] Valid Loss : {loss:.4f}\")\n",
    "\n",
    "    valid_loss /= len(dataloader)\n",
    "    valid_acc = accuracy_score(preds_list, targets_list)\n",
    "    valid_f1 = f1_score(preds_list, targets_list, average='macro')\n",
    "\n",
    "    metrics = {\n",
    "        'valid_loss' : valid_loss,\n",
    "        'valid_acc' : valid_acc,\n",
    "        'valid_f1' : valid_f1\n",
    "    }\n",
    "\n",
    "    return model, metrics\n",
    "\n",
    "def training_loop(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, device, num_epochs, model_path, model_name, patience, run):\n",
    "\n",
    "    best_valid_loss = float('inf')\n",
    "    valid_max_accuracy = -1\n",
    "    valid_max_f1 = -1\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model, train_metrics = training(model, train_dataloader, train_dataset, device, criterion, optimizer, epoch, num_epochs)\n",
    "        model, valid_metrics = evaluation(model, valid_dataloader, valid_dataset, device, criterion, epoch, num_epochs)\n",
    "\n",
    "        monitoring_value = {\n",
    "            'train_loss' : train_metrics['train_loss'],\n",
    "            'train_accuracy' : train_metrics['train_acc'],\n",
    "            'train_f1' : train_metrics['train_f1'],\n",
    "            'valid_loss' : valid_metrics['valid_loss'],\n",
    "            'valid_accuracy' : valid_metrics['valid_acc'],\n",
    "            'valid_f1' : valid_metrics['valid_f1']\n",
    "        }\n",
    "        run.log(monitoring_value, step=epoch)\n",
    "\n",
    "        if valid_max_accuracy < valid_metrics['valid_acc']:\n",
    "            valid_max_accuracy = valid_metrics['valid_acc']\n",
    "\n",
    "            run.summary['best_train_acc'] = train_metrics['train_acc']\n",
    "            run.summary['best_valid_acc'] = valid_metrics['valid_acc']\n",
    "        \n",
    "        if valid_max_f1 < valid_metrics['valid_f1']:\n",
    "            valid_max_f1 = valid_metrics['valid_f1']\n",
    "            torch.save(model.state_dict(), f\"./model_{model_name}.pt\")\n",
    "\n",
    "            run.summary['best_train_f1'] = train_metrics['train_f1']\n",
    "            run.summary['best_valid_f1'] = valid_metrics['valid_f1']\n",
    "\n",
    "        if best_valid_loss > valid_metrics['valid_loss']:\n",
    "            best_valid_loss = valid_metrics['valid_loss']\n",
    "            early_stop_counter = 0\n",
    "            run.summary['best_train_loss'] = train_metrics['train_loss']\n",
    "            run.summary['best_valid_loss'] = valid_metrics['valid_loss']\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss : {train_metrics['train_loss']:.4f}, Train Acc : {train_metrics['train_acc']:.4f}, 'Train F1 : {train_metrics['train_f1']:.4f}, Valid Loss : {valid_metrics['valid_loss']:.4f}, Valid Acc : {valid_metrics['valid_acc']:.4f}, Valid F1 : {valid_metrics['valid_f1']}\")\n",
    "\n",
    "        if early_stop_counter >= patience:\n",
    "            print('Early Stopping!')        \n",
    "            break\n",
    "\n",
    "    return model, valid_max_accuracy, valid_max_f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>target2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>augmented_0_a1ab865095b2d312_ljh.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>augmented_1_a1ab865095b2d312_ljh.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>augmented_2_a1ab865095b2d312_ljh.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>augmented_3_a1ab865095b2d312_ljh.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>augmented_4_a1ab865095b2d312_ljh.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID  target  target2\n",
       "0  augmented_0_a1ab865095b2d312_ljh.jpg       2        2\n",
       "1  augmented_1_a1ab865095b2d312_ljh.jpg       2        2\n",
       "2  augmented_2_a1ab865095b2d312_ljh.jpg       2        2\n",
       "3  augmented_3_a1ab865095b2d312_ljh.jpg       2        2\n",
       "4  augmented_4_a1ab865095b2d312_ljh.jpg       2        2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_csv_path = 'data/dataset_50000/final_df.csv'\n",
    "df_img = pd.read_csv(img_csv_path)\n",
    "df_img.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52608 3140\n"
     ]
    }
   ],
   "source": [
    "img_path = 'data/dataset_50000/aug_2'\n",
    "test_img_path = 'data/test/'\n",
    "totensor_transform = A.Compose([A.Resize(380, 380), ToTensorV2()])\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(380, 380),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "train_dataset = ImageDataset(img_csv_path, img_path, album_transform=totensor_transform, augraphy_transform=None)\n",
    "test_dataset = ImageDataset(submission_path, test_img_path, album_transform=test_transform, augraphy_transform=None)\n",
    "\n",
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ImageDataset1(submission_path, test_img_path, album_transform=test_transform, augraphy_transform=None)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33668 8418\n"
     ]
    }
   ],
   "source": [
    "train_num = int(len(train_dataset) * 0.8)\n",
    "valid_num = len(train_dataset) - train_num\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [train_num, valid_num])\n",
    "\n",
    "print(len(train_dataset), len(valid_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNet(\n",
      "  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNormAct2d(\n",
      "    48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "    (drop): Identity()\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): DepthwiseSeparableConv(\n",
      "        (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(336, 336, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=336, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=960, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (6): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (7): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(1632, 1632, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1632, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (conv_pw): Conv2d(448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNormAct2d(\n",
      "          2688, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (conv_dw): Conv2d(2688, 2688, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2688, bias=False)\n",
      "        (bn2): BatchNormAct2d(\n",
      "          2688, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (se): SqueezeExcite(\n",
      "          (conv_reduce): Conv2d(2688, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act1): SiLU(inplace=True)\n",
      "          (conv_expand): Conv2d(112, 2688, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (gate): Sigmoid()\n",
      "        )\n",
      "        (conv_pwl): Conv2d(2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNormAct2d(\n",
      "          448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (drop): Identity()\n",
      "          (act): Identity()\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn2): BatchNormAct2d(\n",
      "    1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "    (drop): Identity()\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "  (classifier): Linear(in_features=1792, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m timm\u001b[38;5;241m.\u001b[39mcreate_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mefficientnet_b4\u001b[39m\u001b[38;5;124m'\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m in_features \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mclassifier\u001b[38;5;241m.\u001b[39min_features\n\u001b[0;32m----> 4\u001b[0m classifier \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m      5\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(in_features, \u001b[38;5;241m1024\u001b[39m),\n\u001b[1;32m      6\u001b[0m     nn\u001b[38;5;241m.\u001b[39mBatchNorm1d(\u001b[38;5;241m1024\u001b[39m),\n\u001b[1;32m      7\u001b[0m     nn\u001b[38;5;241m.\u001b[39mSiLU(),\n\u001b[1;32m      8\u001b[0m     nn\u001b[38;5;241m.\u001b[39mDropout(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m),\n\u001b[1;32m      9\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m512\u001b[39m),\n\u001b[1;32m     10\u001b[0m     nn\u001b[38;5;241m.\u001b[39mBatchNorm1d(\u001b[38;5;241m512\u001b[39m),\n\u001b[1;32m     11\u001b[0m     nn\u001b[38;5;241m.\u001b[39mSiLU(),\n\u001b[1;32m     12\u001b[0m     nn\u001b[38;5;241m.\u001b[39mDropout(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m),\n\u001b[1;32m     13\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m256\u001b[39m),\n\u001b[1;32m     14\u001b[0m     nn\u001b[38;5;241m.\u001b[39mBatchNorm1d(\u001b[38;5;241m256\u001b[39m),\n\u001b[1;32m     15\u001b[0m     nn\u001b[38;5;241m.\u001b[39mSiLU(),\n\u001b[1;32m     16\u001b[0m     nn\u001b[38;5;241m.\u001b[39mDropout(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m),\n\u001b[1;32m     17\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m17\u001b[39m),\n\u001b[1;32m     18\u001b[0m ) \n\u001b[1;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39mclassifier \u001b[38;5;241m=\u001b[39m classifier\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "model = timm.create_model('efficientnet_b4', pretrained=True)\n",
    "in_features = model.classifier.in_features\n",
    "classifier = nn.Sequential(\n",
    "    nn.Linear(in_features, 1024),\n",
    "    nn.BatchNorm1d(1024),\n",
    "    nn.SiLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.SiLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.SiLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(256, 17),\n",
    ") \n",
    "\n",
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cfg():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    num_epochs = 100\n",
    "    batch_size=32\n",
    "    model_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6753ba5564e941c29ac17731b3b6152b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.007 MB of 0.007 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">effb4_add_fc1</strong> at: <a href='https://wandb.ai/hewberryd8/aistages-OCR/runs/37vabucg' target=\"_blank\">https://wandb.ai/hewberryd8/aistages-OCR/runs/37vabucg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240214_152006-37vabucg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ghcexaux) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7211c7033f436491b87b3c3a473d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.007 MB of 0.007 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁█</td></tr><tr><td>train_f1</td><td>▁█</td></tr><tr><td>train_loss</td><td>█▁</td></tr><tr><td>valid_accuracy</td><td>▁█</td></tr><tr><td>valid_f1</td><td>▁█</td></tr><tr><td>valid_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_train_acc</td><td>0.98917</td></tr><tr><td>best_train_f1</td><td>0.98921</td></tr><tr><td>best_train_loss</td><td>0.03841</td></tr><tr><td>best_valid_acc</td><td>0.98926</td></tr><tr><td>best_valid_f1</td><td>0.9892</td></tr><tr><td>best_valid_loss</td><td>0.03491</td></tr><tr><td>train_accuracy</td><td>0.98917</td></tr><tr><td>train_f1</td><td>0.98921</td></tr><tr><td>train_loss</td><td>0.03841</td></tr><tr><td>valid_accuracy</td><td>0.98926</td></tr><tr><td>valid_f1</td><td>0.9892</td></tr><tr><td>valid_loss</td><td>0.03491</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">effb4_add_fc1_50000</strong> at: <a href='https://wandb.ai/hewberryd8/aistages-OCR/runs/ghcexaux' target=\"_blank\">https://wandb.ai/hewberryd8/aistages-OCR/runs/ghcexaux</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240214_152247-ghcexaux/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ghcexaux). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "140485f9f46c4a14bfa3c21f653668ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011114635173645285, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/wandb/run-20240214_154828-egzpmnis</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hewberryd8/aistages-OCR/runs/egzpmnis' target=\"_blank\">effb4_add_fc1_50000</a></strong> to <a href='https://wandb.ai/hewberryd8/aistages-OCR' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hewberryd8/aistages-OCR' target=\"_blank\">https://wandb.ai/hewberryd8/aistages-OCR</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hewberryd8/aistages-OCR/runs/egzpmnis' target=\"_blank\">https://wandb.ai/hewberryd8/aistages-OCR/runs/egzpmnis</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss : 0.1208: 100%|██████████| 1316/1316 [09:15<00:00,  2.37it/s]\n",
      "Epcoh [1/100] Valid Loss : 0.0026: 100%|██████████| 329/329 [01:44<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss : 0.0304, Train Acc : 0.9902, 'Train F1 : 0.9902, Valid Loss : 0.0338, Valid Acc : 0.9905, Valid F1 : 0.9904273950007491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Train Loss : 0.6793: 100%|██████████| 1316/1316 [09:13<00:00,  2.38it/s]\n",
      "Epcoh [2/100] Valid Loss : 0.0007: 100%|██████████| 329/329 [01:46<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Train Loss : 0.0282, Train Acc : 0.9918, 'Train F1 : 0.9919, Valid Loss : 0.0592, Valid Acc : 0.9829, Valid F1 : 0.982676661734145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Train Loss : 0.8553: 100%|██████████| 1316/1316 [09:14<00:00,  2.37it/s]\n",
      "Epcoh [3/100] Valid Loss : 0.0015: 100%|██████████| 329/329 [01:47<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Train Loss : 0.0248, Train Acc : 0.9927, 'Train F1 : 0.9928, Valid Loss : 0.0430, Valid Acc : 0.9878, Valid F1 : 0.9877564238916312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Train Loss : 0.3041: 100%|██████████| 1316/1316 [09:12<00:00,  2.38it/s]\n",
      "Epcoh [4/100] Valid Loss : 0.0004: 100%|██████████| 329/329 [01:45<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Train Loss : 0.0280, Train Acc : 0.9922, 'Train F1 : 0.9922, Valid Loss : 0.0436, Valid Acc : 0.9903, Valid F1 : 0.9902489850247006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Train Loss : 0.0259: 100%|██████████| 1316/1316 [09:14<00:00,  2.37it/s]\n",
      "Epcoh [5/100] Valid Loss : 0.0008: 100%|██████████| 329/329 [01:48<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Train Loss : 0.0216, Train Acc : 0.9942, 'Train F1 : 0.9942, Valid Loss : 0.0303, Valid Acc : 0.9912, Valid F1 : 0.9910926206600552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Train Loss : 0.0237: 100%|██████████| 1316/1316 [09:22<00:00,  2.34it/s]\n",
      "Epcoh [6/100] Valid Loss : 0.0017: 100%|██████████| 329/329 [01:47<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Train Loss : 0.0191, Train Acc : 0.9945, 'Train F1 : 0.9945, Valid Loss : 0.0337, Valid Acc : 0.9910, Valid F1 : 0.9909085023022205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Train Loss : 0.0006: 100%|██████████| 1316/1316 [09:31<00:00,  2.30it/s]\n",
      "Epcoh [7/100] Valid Loss : 0.0000: 100%|██████████| 329/329 [01:50<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Train Loss : 0.0176, Train Acc : 0.9946, 'Train F1 : 0.9946, Valid Loss : 0.0406, Valid Acc : 0.9880, Valid F1 : 0.9879134135344434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Train Loss : 0.0071: 100%|██████████| 1316/1316 [09:29<00:00,  2.31it/s]\n",
      "Epcoh [8/100] Valid Loss : 0.0002: 100%|██████████| 329/329 [01:48<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Train Loss : 0.0183, Train Acc : 0.9948, 'Train F1 : 0.9948, Valid Loss : 0.0244, Valid Acc : 0.9931, Valid F1 : 0.9930151008311725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Train Loss : 0.0595: 100%|██████████| 1316/1316 [09:29<00:00,  2.31it/s]\n",
      "Epcoh [9/100] Valid Loss : 0.0009: 100%|██████████| 329/329 [01:48<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Train Loss : 0.0147, Train Acc : 0.9955, 'Train F1 : 0.9955, Valid Loss : 0.0271, Valid Acc : 0.9938, Valid F1 : 0.9937696722034327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Train Loss : 0.0533: 100%|██████████| 1316/1316 [09:31<00:00,  2.30it/s]\n",
      "Epcoh [10/100] Valid Loss : 0.0008: 100%|██████████| 329/329 [01:48<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Train Loss : 0.0185, Train Acc : 0.9946, 'Train F1 : 0.9946, Valid Loss : 0.0467, Valid Acc : 0.9888, Valid F1 : 0.988558354438753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Train Loss : 0.0002: 100%|██████████| 1316/1316 [09:30<00:00,  2.31it/s]\n",
      "Epcoh [11/100] Valid Loss : 0.0029: 100%|██████████| 329/329 [01:48<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Train Loss : 0.0124, Train Acc : 0.9964, 'Train F1 : 0.9964, Valid Loss : 0.0338, Valid Acc : 0.9915, Valid F1 : 0.9914965659373542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/100], Train Loss : 2.3352: 100%|██████████| 1316/1316 [09:31<00:00,  2.30it/s]\n",
      "Epcoh [12/100] Valid Loss : 0.0001: 100%|██████████| 329/329 [01:48<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100], Train Loss : 0.0156, Train Acc : 0.9966, 'Train F1 : 0.9966, Valid Loss : 0.0394, Valid Acc : 0.9891, Valid F1 : 0.989006894638645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/100], Train Loss : 0.0159:  43%|████▎     | 569/1316 [04:07<05:24,  2.30it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m model1 \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# run.watch(model1, criterion, log='all', log_graph=True)\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m model, valid_max_accuracy, valid_max_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m run\u001b[38;5;241m.\u001b[39mfinish()\n",
      "Cell \u001b[0;32mIn[20], line 77\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, device, num_epochs, model_path, model_name, patience, run)\u001b[0m\n\u001b[1;32m     74\u001b[0m early_stop_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 77\u001b[0m     model, train_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     model, valid_metrics \u001b[38;5;241m=\u001b[39m evaluation(model, valid_dataloader, valid_dataset, device, criterion, epoch, num_epochs)\n\u001b[1;32m     80\u001b[0m     monitoring_value \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m : train_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m : train_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_f1\u001b[39m\u001b[38;5;124m'\u001b[39m : valid_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_f1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     87\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[20], line 19\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model, dataloader, dataset, device, criterion, optimizer, epoch, num_epochs)\u001b[0m\n\u001b[1;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 19\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m preds_list\u001b[38;5;241m.\u001b[39mextend(outputs\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     21\u001b[0m targets_list\u001b[38;5;241m.\u001b[39mextend(labels\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run = wandb.init(project='aistages-OCR', name='effb4_add_fc1_50000')\n",
    "\n",
    "device = Cfg.device\n",
    "model = Cfg.model\n",
    "criterion = Cfg.criterion\n",
    "optimizer = Cfg.optimizer \n",
    "num_epochs = Cfg.num_epochs\n",
    "model_name = 'effb4-add_fc_50000dataset'\n",
    "model_path = Cfg.model_path\n",
    "model1 = model\n",
    "# run.watch(model1, criterion, log='all', log_graph=True)\n",
    "\n",
    "model, valid_max_accuracy, valid_max_f1 = training_loop(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, device, num_epochs, model_path, model_name, 20, run)\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run = wandb.init(project='AIStage-CV', name='effb4_add_fc')\n",
    "\n",
    "# device = Cfg.device\n",
    "# model = Cfg.model\n",
    "# criterion = Cfg.criterion\n",
    "# optimizer = Cfg.optimizer \n",
    "# num_epochs = Cfg.num_epochs\n",
    "# model_name = 'effb4-add_fc'\n",
    "# model_path = Cfg.model_path\n",
    "\n",
    "# run.watch(model, criterion, log='all', log_graph=True)\n",
    "\n",
    "# model, valid_max_accuracy, valid_max_f1 = training_loop(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, device, num_epochs, model_path, model_name, 20, run)\n",
    "\n",
    "# run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNormAct2d(\n",
       "    48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "    (drop): Identity()\n",
       "    (act): SiLU(inplace=True)\n",
       "  )\n",
       "  (blocks): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(336, 336, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=336, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1632, 1632, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1632, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          2688, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(2688, 2688, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2688, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          2688, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(2688, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(112, 2688, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_head): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn2): BatchNormAct2d(\n",
       "    1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "    (drop): Identity()\n",
       "    (act): SiLU(inplace=True)\n",
       "  )\n",
       "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1792, out_features=1024, bias=True)\n",
       "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): SiLU()\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): SiLU()\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): SiLU()\n",
       "    (11): Dropout(p=0.2, inplace=False)\n",
       "    (12): Linear(in_features=256, out_features=17, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effb4 = timm.create_model('efficientnet_b4', pretrained=True)\n",
    "in_features = effb4.classifier.in_features\n",
    "classifier = nn.Sequential(\n",
    "    nn.Linear(in_features, 1024),\n",
    "    nn.BatchNorm1d(1024),\n",
    "    nn.SiLU(), # relu -> swish 변경 \n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.SiLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.SiLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(256, 17),\n",
    ")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "effb4.classifier = classifier\n",
    "effb4.load_state_dict(torch.load(f'./model_effb4-add_fc_50000dataset.pt'))\n",
    "effb4 = effb4.to(device)\n",
    "effb4.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Albumentations 변환 정의\n",
    "transform_tta = A.Compose([\n",
    "    A.Flip(p=0.5),  # 수평 뒤집기\n",
    "    A.Rotate(limit=279, p=0.5),  # 회전\n",
    "    A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.5),  # 선명하게\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "def apply_tta_and_predict(model, images, num_transforms=3):\n",
    "    \"\"\"TTA를 적용하고, 변환된 이미지들에 대한 예측 결과의 평균을 계산합니다.\"\"\"\n",
    "    batch_size, C, H, W = images.shape\n",
    "    preds = torch.zeros((batch_size, model.num_classes), device=device)\n",
    "    transform_tta = A.Compose([\n",
    "                                A.Flip(p=0.5),  # 수평 뒤집기\n",
    "                                A.Rotate(limit=40, p=0.5),  # 회전\n",
    "                                A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.5),  # 선명하게\n",
    "                                ToTensorV2()  # PyTorch 모델에 사용하기 위해 Tensor로 변환\n",
    "                            ])\n",
    "    for _ in range(num_transforms):\n",
    "        # Albumentations는 numpy 이미지를 요구하므로, PyTorch 텐서를 numpy 배열로 변환합니다.\n",
    "        images_np = images.cpu().numpy().transpose(0, 2, 3, 1)  # CHW -> HWC\n",
    "        augmented_images = np.zeros((batch_size, C, H, W), dtype=np.float32)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            augmented = transform_tta(image=images_np[i])['image']\n",
    "            augmented_images[i] = augmented\n",
    "        \n",
    "        augmented_images = torch.from_numpy(augmented_images.transpose(0, 3, 1, 2)).to(device)  # HWC -> CHW\n",
    "        with torch.no_grad():\n",
    "            preds += model(augmented_images)\n",
    "    \n",
    "    preds /= num_transforms\n",
    "    return preds.argmax(dim=1).detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/99 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) /io/opencv/modules/core/src/matrix_transform.cpp:782: error: (-215:Assertion failed) _src.dims() <= 2 in function 'flip'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      7\u001b[0m     images_np \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \n\u001b[0;32m----> 8\u001b[0m     transformed_img1 \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_tta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages_np\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m     transformed_img2 \u001b[38;5;241m=\u001b[39m transform_tta(image\u001b[38;5;241m=\u001b[39m images_np)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]    \n\u001b[1;32m     10\u001b[0m     output \u001b[38;5;241m=\u001b[39m effb4(images)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/core/composition.py:210\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[1;32m    207\u001b[0m     p\u001b[38;5;241m.\u001b[39mpreprocess(data)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(transforms):\n\u001b[0;32m--> 210\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_each_transform:\n\u001b[1;32m    213\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data_post_transform(data)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/core/transforms_interface.py:118\u001b[0m, in \u001b[0;36mBasicTransform.__call__\u001b[0;34m(self, force_apply, *args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m             warn(\n\u001b[1;32m    114\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_class_fullname() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m could work incorrectly in ReplayMode for other input data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m because its\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m params depend on targets.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m             )\n\u001b[1;32m    117\u001b[0m         kwargs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_key][\u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m)] \u001b[38;5;241m=\u001b[39m deepcopy(params)\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_with_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m kwargs\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/core/transforms_interface.py:131\u001b[0m, in \u001b[0;36mBasicTransform.apply_with_params\u001b[0;34m(self, params, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m     target_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_target_function(key)\n\u001b[1;32m    130\u001b[0m     target_dependencies \u001b[38;5;241m=\u001b[39m {k: kwargs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_dependence\u001b[38;5;241m.\u001b[39mget(key, [])}\n\u001b[0;32m--> 131\u001b[0m     res[key] \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtarget_dependencies\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     res[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/geometric/transforms.py:1263\u001b[0m, in \u001b[0;36mFlip.apply\u001b[0;34m(self, img, d, **params)\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, img: np\u001b[38;5;241m.\u001b[39mndarray, d: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Args:\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;124;03m    d (int): code that specifies how to flip the input. 0 for vertical flipping, 1 for horizontal flipping,\u001b[39;00m\n\u001b[1;32m   1260\u001b[0m \u001b[38;5;124;03m            -1 for both vertical and horizontal flipping (which is also could be seen as rotating the input by\u001b[39;00m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;124;03m            180 degrees).\u001b[39;00m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_flip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/utils.py:107\u001b[0m, in \u001b[0;36mpreserve_shape.<locals>.wrapped_function\u001b[0;34m(img, *args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_function\u001b[39m(img: np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    106\u001b[0m     shape \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 107\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreshape(shape)\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/geometric/functional.py:878\u001b[0m, in \u001b[0;36mrandom_flip\u001b[0;34m(img, code)\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;129m@preserve_shape\u001b[39m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrandom_flip\u001b[39m(img: np\u001b[38;5;241m.\u001b[39mndarray, code: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m--> 878\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) /io/opencv/modules/core/src/matrix_transform.cpp:782: error: (-215:Assertion failed) _src.dims() <= 2 in function 'flip'\n"
     ]
    }
   ],
   "source": [
    "preds_list = []\n",
    "\n",
    "# Albumentations 변환 정의\n",
    "transform_tta = A.Compose([\n",
    "    A.Flip(p=0.5),  # 수평 뒤집기\n",
    "    A.Rotate(limit=279, p=0.5),  # 회전\n",
    "    A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.5),  # 선명하게\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "for images, labels in tqdm(test_dataloader):\n",
    "    images = images.type(torch.cuda.FloatTensor)\n",
    "    images = images.to(device)\n",
    "    with torch.no_grad():\n",
    "        images_np = images.permute(0, 2, 3, 1).cpu().numpy() \n",
    "        transformed_img1 = transform_tta(image = images_np)['image']\n",
    "        transformed_img2 = transform_tta(image= images_np)['image']    \n",
    "        output = effb4(images)\n",
    "        output_img1 = effb4(torch.tensor(transformed_img1).to(device))\n",
    "        output_img2 = effb4(torch.tensor(transformed_img2).to(device))\n",
    "        preds = (output + output_img1 + output_img2)/3\n",
    "        \n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:37<00:00,  1.01it/s]\n"
     ]
    }
   ],
   "source": [
    "preds_list = []\n",
    "\n",
    "# Albumentations 변환 정의\n",
    "transform_tta = A.Compose([\n",
    "    A.Flip(p=0.5),  # 수평 뒤집기\n",
    "    A.Rotate(limit=279, p=0.5),  # 회전\n",
    "    A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.5),  # 선명하게\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "for images, labels in tqdm(test_dataloader):\n",
    "    images = images.float().to(device)\n",
    "    with torch.no_grad():\n",
    "        # 이미지 배치를 CPU로 이동시키고 NumPy 배열로 변환\n",
    "        images_np = images.cpu().numpy()\n",
    "        #print(images_np.shape)  32,3,380,380\n",
    "        # 변환된 이미지를 저장할 배열 초기화\n",
    "        transformed_imgs1 = []\n",
    "        transformed_imgs2 = []\n",
    "        \n",
    "        # 각 이미지에 대해 변환 적용\n",
    "        for img_np in images_np:\n",
    "            # 이미지 하나에 대해 변환 적용\n",
    "            # print(img_np.shape) 3,380,380\n",
    "            transformed_data1 = transform_tta(image=img_np)\n",
    "            transformed_data2 = transform_tta(image=img_np)\n",
    "            \n",
    "            # 변환된 이미지 배열에 추가\n",
    "            transformed_imgs1.append(transformed_data1['image'].permute(1,0,2))\n",
    "            transformed_imgs2.append(transformed_data2['image'].permute(1,0,2))\n",
    "            \n",
    "        \n",
    "        # NumPy 배열로 변환된 이미지들을 PyTorch 텐서로 변환\n",
    "        transformed_img1 = torch.tensor(np.array(transformed_imgs1), dtype=torch.float).to(device)\n",
    "        transformed_img2 = torch.tensor(np.array(transformed_imgs2), dtype=torch.float).to(device)\n",
    "        \n",
    "        # 모델 예측 수행\n",
    "        output = effb4(images)\n",
    "        output_img1 = effb4(transformed_img1)\n",
    "        output_img2 = effb4(transformed_img2)\n",
    "        \n",
    "        # 예측 결과 평균 계산\n",
    "        preds = (output + output_img1 + output_img2) / 3\n",
    "        \n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008fdb22ddce0ce.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091bffdffd83de.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00396fbc1f6cc21d.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00471f8038d9c4b6.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00901f504008d884.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID  target\n",
       "0  0008fdb22ddce0ce.jpg       2\n",
       "1  00091bffdffd83de.jpg      12\n",
       "2  00396fbc1f6cc21d.jpg       5\n",
       "3  00471f8038d9c4b6.jpg      12\n",
       "4  00901f504008d884.jpg       2"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list\n",
    "sample_submission_df = pd.read_csv(submission_path)\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()\n",
    "pred_df.to_csv('./effb4-add_50000_3tta_notnormalize.csv', index=False)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:29<00:00,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "preds_list = []\n",
    "\n",
    "# Albumentations 변환 정의\n",
    "transform_tta = A.Compose([\n",
    "    A.Flip(p=0.5),  # 수평 뒤집기\n",
    "    A.Rotate(limit=279, p=0.5),  # 회전\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "for images, labels in tqdm(test_dataloader):\n",
    "    images = images.float().to(device)\n",
    "    with torch.no_grad():\n",
    "        # 이미지 배치를 CPU로 이동시키고 NumPy 배열로 변환\n",
    "        images_np = images.cpu().numpy()\n",
    "        #print(images_np.shape)  32,3,380,380\n",
    "        # 변환된 이미지를 저장할 배열 초기화\n",
    "        transformed_imgs1 = []\n",
    "        transformed_imgs2 = []\n",
    "        \n",
    "        # 각 이미지에 대해 변환 적용\n",
    "        for img_np in images_np:\n",
    "            # 이미지 하나에 대해 변환 적용\n",
    "            # print(img_np.shape) 3,380,380\n",
    "            transformed_data1 = transform_tta(image=img_np)\n",
    "            transformed_data2 = transform_tta(image=img_np)\n",
    "            \n",
    "            # 변환된 이미지 배열에 추가\n",
    "            transformed_imgs1.append(transformed_data1['image'].permute(1,0,2))\n",
    "            transformed_imgs2.append(transformed_data2['image'].permute(1,0,2))\n",
    "            \n",
    "        \n",
    "        # NumPy 배열로 변환된 이미지들을 PyTorch 텐서로 변환\n",
    "        transformed_img1 = torch.tensor(np.array(transformed_imgs1), dtype=torch.float).to(device)\n",
    "        transformed_img2 = torch.tensor(np.array(transformed_imgs2), dtype=torch.float).to(device)\n",
    "        \n",
    "        # 모델 예측 수행\n",
    "        output = effb4(images)\n",
    "        output_img1 = effb4(transformed_img1)\n",
    "        output_img2 = effb4(transformed_img2)\n",
    "        \n",
    "        # 예측 결과 평균 계산\n",
    "        preds = (output + output_img1 + output_img2) / 3\n",
    "        \n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008fdb22ddce0ce.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091bffdffd83de.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00396fbc1f6cc21d.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00471f8038d9c4b6.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00901f504008d884.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID  target\n",
       "0  0008fdb22ddce0ce.jpg       2\n",
       "1  00091bffdffd83de.jpg      12\n",
       "2  00396fbc1f6cc21d.jpg       5\n",
       "3  00471f8038d9c4b6.jpg      12\n",
       "4  00901f504008d884.jpg       2"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list\n",
    "sample_submission_df = pd.read_csv(submission_path)\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()\n",
    "pred_df.to_csv('./effb4-add_50000_3tta_notsharpennotnormalize.csv', index=False)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:48<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "preds_list = []\n",
    "\n",
    "# Albumentations 변환 정의\n",
    "transform_tta_1 = A.Compose([\n",
    "    A.HorizontalFlip(p=1.0),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "transform_tta_2 = A.Compose([\n",
    "    A.VerticalFlip(p=1.0),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "transform_tta_3 = A.Compose([\n",
    "    A.Rotate(limit=359, p=1.0),  # 회전\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "for images, labels in tqdm(test_dataloader):\n",
    "    images = images.float().to(device)\n",
    "    with torch.no_grad():\n",
    "        # 이미지 배치를 CPU로 이동시키고 NumPy 배열로 변환\n",
    "        images_np = images.cpu().numpy()\n",
    "        #print(images_np.shape)  32,3,380,380\n",
    "        # 변환된 이미지를 저장할 배열 초기화\n",
    "        transformed_imgs1 = []\n",
    "        transformed_imgs2 = []\n",
    "        transformed_imgs3 = []\n",
    "        \n",
    "        \n",
    "        # 각 이미지에 대해 변환 적용\n",
    "        for img_np in images_np:\n",
    "            # 이미지 하나에 대해 변환 적용\n",
    "            # print(img_np.shape) 3,380,380\n",
    "            transformed_data1 = transform_tta_1(image=img_np)\n",
    "            transformed_data2 = transform_tta_2(image=img_np)\n",
    "            transformed_data3 = transform_tta_3(image=img_np)\n",
    "            \n",
    "            # 변환된 이미지 배열에 추가\n",
    "            transformed_imgs1.append(transformed_data1['image'].permute(1,0,2))\n",
    "            transformed_imgs2.append(transformed_data2['image'].permute(1,0,2))\n",
    "            transformed_imgs3.append(transformed_data3['image'].permute(1,0,2))\n",
    "            \n",
    "        \n",
    "        # NumPy 배열로 변환된 이미지들을 PyTorch 텐서로 변환\n",
    "        transformed_img1 = torch.tensor(np.array(transformed_imgs1), dtype=torch.float).to(device)\n",
    "        transformed_img2 = torch.tensor(np.array(transformed_imgs2), dtype=torch.float).to(device)\n",
    "        transformed_img3 = torch.tensor(np.array(transformed_imgs3), dtype=torch.float).to(device)\n",
    "        \n",
    "        # 모델 예측 수행\n",
    "        output = effb4(images)\n",
    "        output_img1 = effb4(transformed_img1)\n",
    "        output_img2 = effb4(transformed_img2)\n",
    "        output_img3 = effb4(transformed_img3)\n",
    "        \n",
    "        # 예측 결과 평균 계산\n",
    "        preds = (output + output_img1 + output_img2+output_img3) / 4\n",
    "        \n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008fdb22ddce0ce.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091bffdffd83de.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00396fbc1f6cc21d.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00471f8038d9c4b6.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00901f504008d884.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID  target\n",
       "0  0008fdb22ddce0ce.jpg       2\n",
       "1  00091bffdffd83de.jpg      12\n",
       "2  00396fbc1f6cc21d.jpg       5\n",
       "3  00471f8038d9c4b6.jpg      12\n",
       "4  00901f504008d884.jpg       2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list\n",
    "sample_submission_df = pd.read_csv(submission_path)\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()\n",
    "pred_df.to_csv('./effb4-add_50000_4tta_fliprotatenotnormalize.csv', index=False)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [02:42<00:00,  1.64s/it]\n"
     ]
    }
   ],
   "source": [
    "preds_list = []\n",
    "\n",
    "# Albumentations 변환 정의\n",
    "transform_tta_1 = A.Compose([\n",
    "    A.HorizontalFlip(p=1.0),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "transform_tta_2 = A.Compose([\n",
    "    A.VerticalFlip(p=1.0),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "transform_tta_3 = A.Compose([\n",
    "    A.Rotate(limit=359, p=1.0),  # 회전\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "for images, labels in tqdm(test_dataloader):\n",
    "    images = images.float().to(device)\n",
    "    with torch.no_grad():\n",
    "        # 이미지 배치를 CPU로 이동시키고 NumPy 배열로 변환\n",
    "        images_np = images.cpu().numpy()\n",
    "        #print(images_np.shape)  32,3,380,380\n",
    "        # 변환된 이미지를 저장할 배열 초기화\n",
    "        transformed_imgs1 = []\n",
    "        transformed_imgs2 = []\n",
    "        transformed_imgs3 = []\n",
    "        transformed_imgs4 = []\n",
    "        transformed_imgs5 = []\n",
    "        \n",
    "        \n",
    "        # 각 이미지에 대해 변환 적용\n",
    "        for img_np in images_np:\n",
    "            # 이미지 하나에 대해 변환 적용\n",
    "            # print(img_np.shape) 3,380,380\n",
    "            transformed_data1 = transform_tta_1(image=img_np)\n",
    "            transformed_data2 = transform_tta_2(image=img_np)\n",
    "            transformed_data3 = transform_tta_3(image=img_np)\n",
    "            transformed_data4 = transform_tta_4(image=img_np)\n",
    "            transformed_data5 = transform_tta_5(image=img_np)\n",
    "            \n",
    "            # 변환된 이미지 배열에 추가\n",
    "            transformed_imgs1.append(transformed_data1['image'].permute(1,0,2))\n",
    "            transformed_imgs2.append(transformed_data2['image'].permute(1,0,2))\n",
    "            transformed_imgs3.append(transformed_data3['image'].permute(1,0,2))\n",
    "            transformed_imgs4.append(transformed_data4['image'].permute(1,0,2))\n",
    "            transformed_imgs5.append(transformed_data5['image'].permute(1,0,2))\n",
    "            \n",
    "        \n",
    "        # NumPy 배열로 변환된 이미지들을 PyTorch 텐서로 변환\n",
    "        transformed_img1 = torch.tensor(np.array(transformed_imgs1), dtype=torch.float).to(device)\n",
    "        transformed_img2 = torch.tensor(np.array(transformed_imgs2), dtype=torch.float).to(device)\n",
    "        transformed_img3 = torch.tensor(np.array(transformed_imgs3), dtype=torch.float).to(device)\n",
    "        transformed_img4 = torch.tensor(np.array(transformed_imgs4), dtype=torch.float).to(device)        \n",
    "        transformed_img5 = torch.tensor(np.array(transformed_imgs5), dtype=torch.float).to(device)        \n",
    "        \n",
    "        # 모델 예측 수행\n",
    "        output = effb4(images)\n",
    "        output_img1 = effb4(transformed_img1)\n",
    "        output_img2 = effb4(transformed_img2)\n",
    "        output_img3 = effb4(transformed_img3)\n",
    "        output_img4 = effb4(transformed_img4)\n",
    "        output_img5 = effb4(transformed_img5)\n",
    "        \n",
    "        \n",
    "        output_probs = F.softmax(output, dim=1)\n",
    "        output_img1_probs = F.softmax(output_img1, dim=1)\n",
    "        output_img2_probs = F.softmax(output_img2, dim=1)\n",
    "        output_img3_probs = F.softmax(output_img3, dim=1)\n",
    "        output_img4_probs = F.softmax(output_img4, dim=1)\n",
    "        output_img5_probs = F.softmax(output_img5, dim=1)\n",
    "        \n",
    "        # 각 샘플별로 최대 확률 계산\n",
    "        max_probs, _ = torch.max(output_probs, dim=1)\n",
    "        \n",
    "        # 확률이 0.95 이상인 샘플의 인덱스\n",
    "        high_confidence_indices = max_probs >= 0.95\n",
    "        # 확률이 0.95 미만인 샘플의 인덱스\n",
    "        low_confidence_indices = max_probs < 0.95\n",
    "        \n",
    "        # 확률이 0.95 이상인 샘플에 대한 최종 예측\n",
    "        final_preds = output_probs.argmax(dim=1)\n",
    "        \n",
    "        # 확률이 0.95 미만인 샘플에 대한 예측은 변환된 이미지들의 예측 확률 평균을 사용\n",
    "        if low_confidence_indices.sum() > 0:\n",
    "            avg_probs = (output_img1_probs + output_img2_probs + output_img3_probs )/3\n",
    "            avg_final_preds = avg_probs.argmax(dim=1)\n",
    "            \n",
    "            # 확률이 0.95 미만인 샘플에 대해 평균 예측으로 최종 예측 업데이트\n",
    "            final_preds[low_confidence_indices] = avg_final_preds[low_confidence_indices]\n",
    "        \n",
    "        # 최종 예측 리스트에 추가\n",
    "        preds_list.extend(final_preds.cpu().numpy())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 12,\n",
       " 5,\n",
       " 12,\n",
       " 2,\n",
       " 15,\n",
       " 0,\n",
       " 8,\n",
       " 15,\n",
       " 11,\n",
       " 5,\n",
       " 3,\n",
       " 16,\n",
       " 9,\n",
       " 15,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 13,\n",
       " 10,\n",
       " 12,\n",
       " 12,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 14,\n",
       " 16,\n",
       " 12,\n",
       " 6,\n",
       " 7,\n",
       " 0,\n",
       " 13,\n",
       " 2,\n",
       " 5,\n",
       " 16,\n",
       " 13,\n",
       " 14,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 9,\n",
       " 12,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 5,\n",
       " 0,\n",
       " 11,\n",
       " 14,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 4,\n",
       " 12,\n",
       " 9,\n",
       " 5,\n",
       " 13,\n",
       " 13,\n",
       " 12,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 7,\n",
       " 10,\n",
       " 6,\n",
       " 3,\n",
       " 10,\n",
       " 8,\n",
       " 15,\n",
       " 14,\n",
       " 15,\n",
       " 6,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 10,\n",
       " 10,\n",
       " 5,\n",
       " 13,\n",
       " 10,\n",
       " 0,\n",
       " 10,\n",
       " 8,\n",
       " 5,\n",
       " 15,\n",
       " 14,\n",
       " 16,\n",
       " 11,\n",
       " 11,\n",
       " 14,\n",
       " 11,\n",
       " 14,\n",
       " 7,\n",
       " 13,\n",
       " 1,\n",
       " 15,\n",
       " 11,\n",
       " 2,\n",
       " 12,\n",
       " 16,\n",
       " 8,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 12,\n",
       " 16,\n",
       " 2,\n",
       " 7,\n",
       " 11,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 8,\n",
       " 10,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 15,\n",
       " 10,\n",
       " 16,\n",
       " 16,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 13,\n",
       " 2,\n",
       " 12,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 9,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 16,\n",
       " 12,\n",
       " 11,\n",
       " 16,\n",
       " 9,\n",
       " 15,\n",
       " 6,\n",
       " 8,\n",
       " 5,\n",
       " 5,\n",
       " 10,\n",
       " 10,\n",
       " 16,\n",
       " 15,\n",
       " 9,\n",
       " 12,\n",
       " 16,\n",
       " 5,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 16,\n",
       " 9,\n",
       " 8,\n",
       " 16,\n",
       " 16,\n",
       " 7,\n",
       " 4,\n",
       " 11,\n",
       " 15,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 11,\n",
       " 10,\n",
       " 9,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 16,\n",
       " 5,\n",
       " 14,\n",
       " 15,\n",
       " 5,\n",
       " 12,\n",
       " 0,\n",
       " 4,\n",
       " 13,\n",
       " 2,\n",
       " 6,\n",
       " 16,\n",
       " 16,\n",
       " 10,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 10,\n",
       " 5,\n",
       " 1,\n",
       " 14,\n",
       " 3,\n",
       " 11,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 13,\n",
       " 12,\n",
       " 0,\n",
       " 16,\n",
       " 3,\n",
       " 12,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 14,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 12,\n",
       " 12,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 15,\n",
       " 10,\n",
       " 14,\n",
       " 9,\n",
       " 11,\n",
       " 12,\n",
       " 0,\n",
       " 1,\n",
       " 11,\n",
       " 12,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 14,\n",
       " 15,\n",
       " 4,\n",
       " 12,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 15,\n",
       " 13,\n",
       " 11,\n",
       " 6,\n",
       " 12,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 12,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 12,\n",
       " 4,\n",
       " 15,\n",
       " 9,\n",
       " 15,\n",
       " 15,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 7,\n",
       " 15,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 11,\n",
       " 14,\n",
       " 11,\n",
       " 6,\n",
       " 5,\n",
       " 13,\n",
       " 16,\n",
       " 13,\n",
       " 15,\n",
       " 5,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 16,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 15,\n",
       " 8,\n",
       " 15,\n",
       " 13,\n",
       " 15,\n",
       " 11,\n",
       " 6,\n",
       " 2,\n",
       " 12,\n",
       " 16,\n",
       " 6,\n",
       " 5,\n",
       " 9,\n",
       " 16,\n",
       " 11,\n",
       " 16,\n",
       " 0,\n",
       " 16,\n",
       " 9,\n",
       " 15,\n",
       " 10,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 15,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 13,\n",
       " 3,\n",
       " 1,\n",
       " 16,\n",
       " 10,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 12,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 11,\n",
       " 3,\n",
       " 4,\n",
       " 10,\n",
       " 3,\n",
       " 4,\n",
       " 12,\n",
       " 10,\n",
       " 5,\n",
       " 9,\n",
       " 15,\n",
       " 13,\n",
       " 11,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 16,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 14,\n",
       " 16,\n",
       " 10,\n",
       " 4,\n",
       " 9,\n",
       " 0,\n",
       " 13,\n",
       " 9,\n",
       " 2,\n",
       " 13,\n",
       " 12,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 12,\n",
       " 16,\n",
       " 0,\n",
       " 15,\n",
       " 16,\n",
       " 9,\n",
       " 12,\n",
       " 11,\n",
       " 10,\n",
       " 5,\n",
       " 8,\n",
       " 16,\n",
       " 14,\n",
       " 10,\n",
       " 2,\n",
       " 10,\n",
       " 16,\n",
       " 3,\n",
       " 7,\n",
       " 11,\n",
       " 11,\n",
       " 10,\n",
       " 5,\n",
       " 13,\n",
       " 10,\n",
       " 10,\n",
       " 11,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 14,\n",
       " 14,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 11,\n",
       " 16,\n",
       " 3,\n",
       " 5,\n",
       " 16,\n",
       " 11,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 12,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 11,\n",
       " 15,\n",
       " 7,\n",
       " 14,\n",
       " 2,\n",
       " 11,\n",
       " 3,\n",
       " 6,\n",
       " 11,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 10,\n",
       " 5,\n",
       " 12,\n",
       " 6,\n",
       " 15,\n",
       " 4,\n",
       " 8,\n",
       " 0,\n",
       " 16,\n",
       " 10,\n",
       " 9,\n",
       " 15,\n",
       " 10,\n",
       " 6,\n",
       " 0,\n",
       " 8,\n",
       " 13,\n",
       " 3,\n",
       " 15,\n",
       " 6,\n",
       " 10,\n",
       " 10,\n",
       " 14,\n",
       " 7,\n",
       " 16,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 10,\n",
       " 8,\n",
       " 16,\n",
       " 6,\n",
       " 7,\n",
       " 12,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 6,\n",
       " 12,\n",
       " 13,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 15,\n",
       " 13,\n",
       " 3,\n",
       " 15,\n",
       " 10,\n",
       " 16,\n",
       " 11,\n",
       " 8,\n",
       " 7,\n",
       " 0,\n",
       " 15,\n",
       " 12,\n",
       " 1,\n",
       " 2,\n",
       " 13,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 9,\n",
       " 16,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 10,\n",
       " 3,\n",
       " 14,\n",
       " 11,\n",
       " 6,\n",
       " 2,\n",
       " 12,\n",
       " 12,\n",
       " 15,\n",
       " 11,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 13,\n",
       " 16,\n",
       " 13,\n",
       " 15,\n",
       " 5,\n",
       " 2,\n",
       " 8,\n",
       " 11,\n",
       " 2,\n",
       " 7,\n",
       " 15,\n",
       " 9,\n",
       " 3,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 13,\n",
       " 10,\n",
       " 12,\n",
       " 15,\n",
       " 7,\n",
       " 14,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 16,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 14,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 15,\n",
       " 11,\n",
       " 7,\n",
       " 3,\n",
       " 13,\n",
       " 9,\n",
       " 7,\n",
       " 11,\n",
       " 13,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 15,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 14,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 13,\n",
       " 3,\n",
       " 14,\n",
       " 5,\n",
       " 10,\n",
       " 16,\n",
       " 15,\n",
       " 5,\n",
       " 12,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 8,\n",
       " 16,\n",
       " 16,\n",
       " 7,\n",
       " 10,\n",
       " 0,\n",
       " 15,\n",
       " 3,\n",
       " 12,\n",
       " 14,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 12,\n",
       " 3,\n",
       " 12,\n",
       " 11,\n",
       " 7,\n",
       " 14,\n",
       " 12,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 14,\n",
       " 10,\n",
       " 16,\n",
       " 5,\n",
       " 16,\n",
       " 2,\n",
       " 12,\n",
       " 2,\n",
       " 9,\n",
       " 10,\n",
       " 16,\n",
       " 16,\n",
       " 15,\n",
       " 12,\n",
       " 10,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 11,\n",
       " 4,\n",
       " 13,\n",
       " 16,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 11,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 15,\n",
       " 7,\n",
       " 12,\n",
       " 1,\n",
       " 13,\n",
       " 16,\n",
       " 5,\n",
       " 2,\n",
       " 13,\n",
       " 3,\n",
       " 2,\n",
       " 15,\n",
       " 8,\n",
       " 11,\n",
       " 6,\n",
       " 12,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 14,\n",
       " 6,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 14,\n",
       " 10,\n",
       " 4,\n",
       " 16,\n",
       " 2,\n",
       " 14,\n",
       " 1,\n",
       " 5,\n",
       " 12,\n",
       " 10,\n",
       " 9,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 13,\n",
       " 11,\n",
       " 9,\n",
       " 4,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 7,\n",
       " 13,\n",
       " 16,\n",
       " 5,\n",
       " 11,\n",
       " 14,\n",
       " 3,\n",
       " 12,\n",
       " 12,\n",
       " 1,\n",
       " 12,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 11,\n",
       " 11,\n",
       " 9,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 16,\n",
       " 4,\n",
       " 1,\n",
       " 16,\n",
       " 14,\n",
       " 13,\n",
       " 5,\n",
       " 10,\n",
       " 3,\n",
       " 10,\n",
       " 6,\n",
       " 7,\n",
       " 16,\n",
       " 8,\n",
       " 8,\n",
       " 11,\n",
       " 10,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 0,\n",
       " 12,\n",
       " 3,\n",
       " 12,\n",
       " 7,\n",
       " 9,\n",
       " 14,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 12,\n",
       " 2,\n",
       " 14,\n",
       " 7,\n",
       " 9,\n",
       " 4,\n",
       " 13,\n",
       " 9,\n",
       " 0,\n",
       " 13,\n",
       " 12,\n",
       " 6,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 13,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 15,\n",
       " 15,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 12,\n",
       " 10,\n",
       " 13,\n",
       " 16,\n",
       " 3,\n",
       " 10,\n",
       " 6,\n",
       " 1,\n",
       " 16,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 15,\n",
       " 1,\n",
       " 14,\n",
       " 9,\n",
       " 11,\n",
       " 10,\n",
       " 4,\n",
       " 8,\n",
       " 10,\n",
       " 16,\n",
       " 9,\n",
       " 15,\n",
       " 15,\n",
       " 7,\n",
       " 12,\n",
       " 11,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 11,\n",
       " 16,\n",
       " 16,\n",
       " 1,\n",
       " 14,\n",
       " 9,\n",
       " 15,\n",
       " 11,\n",
       " 5,\n",
       " 15,\n",
       " 2,\n",
       " 0,\n",
       " 10,\n",
       " 1,\n",
       " 15,\n",
       " 1,\n",
       " 8,\n",
       " 11,\n",
       " 16,\n",
       " 11,\n",
       " 9,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 12,\n",
       " 10,\n",
       " 9,\n",
       " 7,\n",
       " 12,\n",
       " 4,\n",
       " 2,\n",
       " 15,\n",
       " 12,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 16,\n",
       " 16,\n",
       " 5,\n",
       " 8,\n",
       " 1,\n",
       " 11,\n",
       " 9,\n",
       " 12,\n",
       " 6,\n",
       " 15,\n",
       " 4,\n",
       " 8,\n",
       " 9,\n",
       " 16,\n",
       " 12,\n",
       " 6,\n",
       " 14,\n",
       " 10,\n",
       " 11,\n",
       " 16,\n",
       " 0,\n",
       " 12,\n",
       " 14,\n",
       " 4,\n",
       " 11,\n",
       " 10,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 5,\n",
       " 11,\n",
       " 3,\n",
       " 13,\n",
       " 8,\n",
       " 10,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 14,\n",
       " 3,\n",
       " 15,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 15,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 16,\n",
       " 11,\n",
       " 15,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 16,\n",
       " 2,\n",
       " 14,\n",
       " 0,\n",
       " 10,\n",
       " 8,\n",
       " 11,\n",
       " 10,\n",
       " 16,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 5,\n",
       " 15,\n",
       " 16,\n",
       " 10,\n",
       " 4,\n",
       " 16,\n",
       " 11,\n",
       " 7,\n",
       " 13,\n",
       " 10,\n",
       " 9,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 14,\n",
       " 15,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008fdb22ddce0ce.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091bffdffd83de.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00396fbc1f6cc21d.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00471f8038d9c4b6.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00901f504008d884.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID  target\n",
       "0  0008fdb22ddce0ce.jpg       2\n",
       "1  00091bffdffd83de.jpg      12\n",
       "2  00396fbc1f6cc21d.jpg       5\n",
       "3  00471f8038d9c4b6.jpg      12\n",
       "4  00901f504008d884.jpg       2"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list\n",
    "sample_submission_df = pd.read_csv(submission_path)\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()\n",
    "pred_df.to_csv('./effb4-add_50000_first1_after.csv', index=False)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [02:39<00:00,  1.61s/it]\n"
     ]
    }
   ],
   "source": [
    "preds_list = []\n",
    "\n",
    "# Albumentations 변환 정의\n",
    "transform_tta_1 = A.Compose([\n",
    "    A.HorizontalFlip(p=1.0),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "transform_tta_2 = A.Compose([\n",
    "    A.VerticalFlip(p=1.0),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "transform_tta_3 = A.Compose([\n",
    "    A.Rotate(limit=359, p=1.0),  # 회전\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "transform_tta_4 = A.Compose([\n",
    "    A.Rotate(limit=179, p=1.0),  # 회전\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "transform_tta_5 = A.Compose([\n",
    "    A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.5),  # 선명하게\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for images, labels in tqdm(test_dataloader):\n",
    "    images = images.float().to(device)\n",
    "    with torch.no_grad():\n",
    "        # 이미지 배치를 CPU로 이동시키고 NumPy 배열로 변환\n",
    "        images_np = images.cpu().numpy()\n",
    "        #print(images_np.shape)  32,3,380,380\n",
    "        # 변환된 이미지를 저장할 배열 초기화\n",
    "        transformed_imgs1 = []\n",
    "        transformed_imgs2 = []\n",
    "        transformed_imgs3 = []\n",
    "        transformed_imgs4 = []\n",
    "        transformed_imgs5 = []\n",
    "        \n",
    "        \n",
    "        # 각 이미지에 대해 변환 적용\n",
    "        for img_np in images_np:\n",
    "            # 이미지 하나에 대해 변환 적용\n",
    "            # print(img_np.shape) 3,380,380\n",
    "            transformed_data1 = transform_tta_1(image=img_np)\n",
    "            transformed_data2 = transform_tta_2(image=img_np)\n",
    "            transformed_data3 = transform_tta_3(image=img_np)\n",
    "            transformed_data4 = transform_tta_4(image=img_np)\n",
    "            transformed_data5 = transform_tta_5(image=img_np)\n",
    "            \n",
    "            # 변환된 이미지 배열에 추가\n",
    "            transformed_imgs1.append(transformed_data1['image'].permute(1,0,2))\n",
    "            transformed_imgs2.append(transformed_data2['image'].permute(1,0,2))\n",
    "            transformed_imgs3.append(transformed_data3['image'].permute(1,0,2))\n",
    "            transformed_imgs4.append(transformed_data4['image'].permute(1,0,2))\n",
    "            transformed_imgs5.append(transformed_data5['image'].permute(1,0,2))\n",
    "            \n",
    "        \n",
    "        # NumPy 배열로 변환된 이미지들을 PyTorch 텐서로 변환\n",
    "        transformed_img1 = torch.tensor(np.array(transformed_imgs1), dtype=torch.float).to(device)\n",
    "        transformed_img2 = torch.tensor(np.array(transformed_imgs2), dtype=torch.float).to(device)\n",
    "        transformed_img3 = torch.tensor(np.array(transformed_imgs3), dtype=torch.float).to(device)\n",
    "        transformed_img4 = torch.tensor(np.array(transformed_imgs4), dtype=torch.float).to(device)        \n",
    "        transformed_img5 = torch.tensor(np.array(transformed_imgs5), dtype=torch.float).to(device)        \n",
    "        \n",
    "        # 모델 예측 수행\n",
    "        output = effb4(images)\n",
    "        output_img1 = effb4(transformed_img1)\n",
    "        output_img2 = effb4(transformed_img2)\n",
    "        output_img3 = effb4(transformed_img3)\n",
    "        output_img4 = effb4(transformed_img4)\n",
    "        output_img5 = effb4(transformed_img5)\n",
    "        \n",
    "        \n",
    "        output_probs = F.softmax(output, dim=1)\n",
    "        output_img1_probs = F.softmax(output_img1, dim=1)\n",
    "        output_img2_probs = F.softmax(output_img2, dim=1)\n",
    "        output_img3_probs = F.softmax(output_img3, dim=1)\n",
    "        output_img4_probs = F.softmax(output_img4, dim=1)\n",
    "        output_img5_probs = F.softmax(output_img5, dim=1)\n",
    "        \n",
    "        # 각 샘플별로 최대 확률 계산\n",
    "        max_probs, _ = torch.max(output_probs, dim=1)\n",
    "        \n",
    "        # 확률이 0.95 이상인 샘플의 인덱스\n",
    "        high_confidence_indices = max_probs >= 0.98\n",
    "        # 확률이 0.95 미만인 샘플의 인덱스\n",
    "        low_confidence_indices = max_probs < 0.98\n",
    "        \n",
    "        # 확률이 0.95 이상인 샘플에 대한 최종 예측\n",
    "        final_preds = output_probs.argmax(dim=1)\n",
    "        \n",
    "        # 확률이 0.95 미만인 샘플에 대한 예측은 변환된 이미지들의 예측 확률 평균을 사용\n",
    "        if low_confidence_indices.sum() > 0:\n",
    "            avg_probs = (output_img1_probs + output_img2_probs + output_img3_probs + output_img4_probs + output_img5_probs) / 5\n",
    "            avg_final_preds = avg_probs.argmax(dim=1)\n",
    "            \n",
    "            # 확률이 0.95 미만인 샘플에 대해 평균 예측으로 최종 예측 업데이트\n",
    "            final_preds[low_confidence_indices] = avg_final_preds[low_confidence_indices]\n",
    "        \n",
    "        # 최종 예측 리스트에 추가\n",
    "        preds_list.extend(final_preds.cpu().numpy())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008fdb22ddce0ce.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091bffdffd83de.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00396fbc1f6cc21d.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00471f8038d9c4b6.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00901f504008d884.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID  target\n",
       "0  0008fdb22ddce0ce.jpg       2\n",
       "1  00091bffdffd83de.jpg      12\n",
       "2  00396fbc1f6cc21d.jpg       5\n",
       "3  00471f8038d9c4b6.jpg      12\n",
       "4  00901f504008d884.jpg       2"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list\n",
    "sample_submission_df = pd.read_csv(submission_path)\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()\n",
    "pred_df.to_csv('./effb4-add_50000_first1_after5tta_mean98cut.csv', index=False)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [03:15<00:00,  1.98s/it]\n"
     ]
    }
   ],
   "source": [
    "preds_list = []\n",
    "\n",
    "# Albumentations 변환 정의\n",
    "transform_tta = A.Compose([\n",
    "    A.Flip(p=0.5),  # 수평 뒤집기\n",
    "    A.Rotate(limit=279, p=0.5),  # 회전\n",
    "    A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.5),  # 선명하게\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "for images, labels in tqdm(test_dataloader):\n",
    "    images = images.float().to(device)\n",
    "    with torch.no_grad():\n",
    "        # 이미지 배치를 CPU로 이동시키고 NumPy 배열로 변환\n",
    "        images_np = images.cpu().numpy()\n",
    "        #print(images_np.shape)  32,3,380,380\n",
    "        # 변환된 이미지를 저장할 배열 초기화\n",
    "        transformed_imgs1 = []\n",
    "        transformed_imgs2 = []\n",
    "        transformed_imgs3 = []\n",
    "        transformed_imgs4 = []\n",
    "        transformed_imgs5 = []\n",
    "        \n",
    "        # 각 이미지에 대해 변환 적용\n",
    "        for img_np in images_np:\n",
    "            # 이미지 하나에 대해 변환 적용\n",
    "            # print(img_np.shape) 3,380,380\n",
    "            transformed_data1 = transform_tta(image=img_np)\n",
    "            transformed_data2 = transform_tta(image=img_np)\n",
    "            transformed_data3 = transform_tta(image=img_np)\n",
    "            transformed_data4 = transform_tta(image=img_np)\n",
    "            transformed_data5 = transform_tta(image=img_np)\n",
    "            \n",
    "            # 변환된 이미지 배열에 추가\n",
    "            transformed_imgs1.append(transformed_data1['image'].permute(1,0,2))\n",
    "            transformed_imgs2.append(transformed_data2['image'].permute(1,0,2))\n",
    "            transformed_imgs3.append(transformed_data3['image'].permute(1,0,2))\n",
    "            transformed_imgs4.append(transformed_data4['image'].permute(1,0,2))\n",
    "            transformed_imgs5.append(transformed_data5['image'].permute(1,0,2))\n",
    "            \n",
    "        \n",
    "        # NumPy 배열로 변환된 이미지들을 PyTorch 텐서로 변환\n",
    "        transformed_img1 = torch.tensor(np.array(transformed_imgs1), dtype=torch.float).to(device) / 255.0\n",
    "        transformed_img2 = torch.tensor(np.array(transformed_imgs2), dtype=torch.float).to(device) / 255.0\n",
    "        transformed_img3 = torch.tensor(np.array(transformed_imgs3), dtype=torch.float).to(device) / 255.0\n",
    "        transformed_img4 = torch.tensor(np.array(transformed_imgs4), dtype=torch.float).to(device) / 255.0\n",
    "        transformed_img5 = torch.tensor(np.array(transformed_imgs5), dtype=torch.float).to(device) / 255.0\n",
    "        \n",
    "        # 모델 예측 수행\n",
    "        output = effb4(images)\n",
    "        output_img1 = effb4(transformed_img1)\n",
    "        output_img2 = effb4(transformed_img2)\n",
    "        output_img3 = effb4(transformed_img3)\n",
    "        output_img4 = effb4(transformed_img4)\n",
    "        output_img5 = effb4(transformed_img5)\n",
    "        \n",
    "        # 예측 결과 평균 계산\n",
    "        preds = (output + output_img1 + output_img2 + output_img3 + output_img4 + output_img5) / 6\n",
    "        \n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008fdb22ddce0ce.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091bffdffd83de.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00396fbc1f6cc21d.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00471f8038d9c4b6.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00901f504008d884.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID  target\n",
       "0  0008fdb22ddce0ce.jpg       2\n",
       "1  00091bffdffd83de.jpg       2\n",
       "2  00396fbc1f6cc21d.jpg       2\n",
       "3  00471f8038d9c4b6.jpg       2\n",
       "4  00901f504008d884.jpg       2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list\n",
    "sample_submission_df = pd.read_csv(submission_path)\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()\n",
    "pred_df.to_csv('./effb4-add_50000_5tta.csv', index=False)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:30<00:00,  3.23it/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [03:15<00:00,  1.97s/it]\n"
     ]
    }
   ],
   "source": [
    "preds_list = []\n",
    "\n",
    "# Albumentations 변환 정의\n",
    "transform_tta = A.Compose([\n",
    "    A.Flip(p=0.9),  # 수평 뒤집기\n",
    "    A.Rotate(limit=279, p=0.6),  # 회전\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "for images, labels in tqdm(test_dataloader):\n",
    "    images = images.float().to(device)\n",
    "    with torch.no_grad():\n",
    "        # 이미지 배치를 CPU로 이동시키고 NumPy 배열로 변환\n",
    "        images_np = images.cpu().numpy()\n",
    "        #print(images_np.shape)  32,3,380,380\n",
    "        # 변환된 이미지를 저장할 배열 초기화\n",
    "        transformed_imgs1 = []\n",
    "        transformed_imgs2 = []\n",
    "        transformed_imgs3 = []\n",
    "        transformed_imgs4 = []\n",
    "        transformed_imgs5 = []\n",
    "        \n",
    "        # 각 이미지에 대해 변환 적용\n",
    "        for img_np in images_np:\n",
    "            # 이미지 하나에 대해 변환 적용\n",
    "            # print(img_np.shape) 3,380,380\n",
    "            transformed_data1 = transform_tta(image=img_np)\n",
    "            transformed_data2 = transform_tta(image=img_np)\n",
    "            transformed_data3 = transform_tta(image=img_np)\n",
    "            transformed_data4 = transform_tta(image=img_np)\n",
    "            transformed_data5 = transform_tta(image=img_np)\n",
    "            \n",
    "            # 변환된 이미지 배열에 추가\n",
    "            transformed_imgs1.append(transformed_data1['image'].permute(1,0,2))\n",
    "            transformed_imgs2.append(transformed_data2['image'].permute(1,0,2))\n",
    "            transformed_imgs3.append(transformed_data3['image'].permute(1,0,2))\n",
    "            transformed_imgs4.append(transformed_data4['image'].permute(1,0,2))\n",
    "            transformed_imgs5.append(transformed_data5['image'].permute(1,0,2))\n",
    "            \n",
    "        \n",
    "        # NumPy 배열로 변환된 이미지들을 PyTorch 텐서로 변환\n",
    "        transformed_img1 = torch.tensor(np.array(transformed_imgs1), dtype=torch.float).to(device)\n",
    "        transformed_img2 = torch.tensor(np.array(transformed_imgs2), dtype=torch.float).to(device)\n",
    "        transformed_img3 = torch.tensor(np.array(transformed_imgs3), dtype=torch.float).to(device)\n",
    "        transformed_img4 = torch.tensor(np.array(transformed_imgs4), dtype=torch.float).to(device)\n",
    "        transformed_img5 = torch.tensor(np.array(transformed_imgs5), dtype=torch.float).to(device)\n",
    "        \n",
    "        # 모델 예측 수행\n",
    "        output = effb4(images)\n",
    "        output_img1 = effb4(transformed_img1)\n",
    "        output_img2 = effb4(transformed_img2)\n",
    "        output_img3 = effb4(transformed_img3)\n",
    "        output_img4 = effb4(transformed_img4)\n",
    "        output_img5 = effb4(transformed_img5)\n",
    "        \n",
    "        # 예측 결과 평균 계산\n",
    "        preds = (output + output_img1 + output_img2 + output_img3 + output_img4 + output_img5) / 6\n",
    "        \n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008fdb22ddce0ce.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091bffdffd83de.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00396fbc1f6cc21d.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00471f8038d9c4b6.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00901f504008d884.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID  target\n",
       "0  0008fdb22ddce0ce.jpg       2\n",
       "1  00091bffdffd83de.jpg      12\n",
       "2  00396fbc1f6cc21d.jpg       5\n",
       "3  00471f8038d9c4b6.jpg      12\n",
       "4  00901f504008d884.jpg       2"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list\n",
    "sample_submission_df = pd.read_csv(submission_path)\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()\n",
    "pred_df.to_csv('./effb4-add_50000_5tta_notsharpennotnormalize.csv', index=False)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:33<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "preds_list = []\n",
    "\n",
    "# Albumentations 변환 정의\n",
    "transform_tta = A.Compose([\n",
    "    A.Flip(p=1.0),  # 수평 뒤집기\n",
    "    A.Rotate(limit=279, p=0.5),  # 회전\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "for images, labels in tqdm(test_dataloader):\n",
    "    images = images.float().to(device)\n",
    "    with torch.no_grad():\n",
    "        # 이미지 배치를 CPU로 이동시키고 NumPy 배열로 변환\n",
    "        images_np = images.cpu().numpy()\n",
    "        #print(images_np.shape)  32,3,380,380\n",
    "        # 변환된 이미지를 저장할 배열 초기화\n",
    "        transformed_imgs1 = []\n",
    "        transformed_imgs2 = []\n",
    "        \n",
    "        # 각 이미지에 대해 변환 적용\n",
    "        for img_np in images_np:\n",
    "            # 이미지 하나에 대해 변환 적용\n",
    "            # print(img_np.shape) 3,380,380\n",
    "            transformed_data1 = transform_tta(image=img_np)\n",
    "            transformed_data2 = transform_tta(image=img_np)\n",
    "            \n",
    "            # 변환된 이미지 배열에 추가\n",
    "            transformed_imgs1.append(transformed_data1['image'].permute(1,0,2))\n",
    "            transformed_imgs2.append(transformed_data2['image'].permute(1,0,2))\n",
    "            \n",
    "        \n",
    "        # NumPy 배열로 변환된 이미지들을 PyTorch 텐서로 변환\n",
    "        transformed_img1 = torch.tensor(np.array(transformed_imgs1), dtype=torch.float).to(device) \n",
    "        transformed_img2 = torch.tensor(np.array(transformed_imgs2), dtype=torch.float).to(device) \n",
    "        \n",
    "        # 모델 예측 수행\n",
    "        \n",
    "                \n",
    "        output = effb4(images)\n",
    "        output_img1 = effb4(transformed_img1)\n",
    "        output_img2 = effb4(transformed_img2)\n",
    "        \n",
    "        # 예측 결과 평균 계산\n",
    "        pred_indices = torch.stack([\n",
    "            output.argmax(dim=1),\n",
    "            output_img1.argmax(dim=1),\n",
    "            output_img2.argmax(dim=1)\n",
    "        ], dim=1)\n",
    "        preds, _ = pred_indices.mode(dim=1)\n",
    "        \n",
    "    preds_list.extend(preds.detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008fdb22ddce0ce.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091bffdffd83de.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00396fbc1f6cc21d.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00471f8038d9c4b6.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00901f504008d884.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID  target\n",
       "0  0008fdb22ddce0ce.jpg       2\n",
       "1  00091bffdffd83de.jpg      12\n",
       "2  00396fbc1f6cc21d.jpg       5\n",
       "3  00471f8038d9c4b6.jpg      12\n",
       "4  00901f504008d884.jpg       2"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list\n",
    "sample_submission_df = pd.read_csv(submission_path)\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()\n",
    "pred_df.to_csv('./effb4-add_50000_3tta_softvoting_notnormalize.csv', index=False)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_list = []\n",
    "\n",
    "# Albumentations 변환 정의\n",
    "transform_tta = A.Compose([\n",
    "    A.Flip(p=1.0),  # 수평 뒤집기\n",
    "    A.Rotate(limit=279, p=0.5),  # 회전\n",
    "\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "for images, labels in tqdm(test_dataloader):\n",
    "    images = images.float().to(device)\n",
    "    with torch.no_grad():\n",
    "        # 이미지 배치를 CPU로 이동시키고 NumPy 배열로 변환\n",
    "        images_np = images.cpu().numpy()\n",
    "        #print(images_np.shape)  32,3,380,380\n",
    "        # 변환된 이미지를 저장할 배열 초기화\n",
    "        transformed_imgs1 = []\n",
    "        transformed_imgs2 = []\n",
    "        \n",
    "        # 각 이미지에 대해 변환 적용\n",
    "        for img_np in images_np:\n",
    "            # 이미지 하나에 대해 변환 적용\n",
    "            # print(img_np.shape) 3,380,380\n",
    "            transformed_data1 = transform_tta(image=img_np)\n",
    "            transformed_data2 = transform_tta(image=img_np)\n",
    "            \n",
    "            # 변환된 이미지 배열에 추가\n",
    "            transformed_imgs1.append(transformed_data1['image'].permute(1,0,2))\n",
    "            transformed_imgs2.append(transformed_data2['image'].permute(1,0,2))\n",
    "            \n",
    "        \n",
    "        # NumPy 배열로 변환된 이미지들을 PyTorch 텐서로 변환\n",
    "        transformed_img1 = torch.tensor(np.array(transformed_imgs1), dtype=torch.float).to(device)\n",
    "        transformed_img2 = torch.tensor(np.array(transformed_imgs2), dtype=torch.float).to(device)\n",
    "        \n",
    "        # 모델 예측 수행\n",
    "        \n",
    "                \n",
    "        output = effb4(images)\n",
    "        output_img1 = effb4(transformed_img1)\n",
    "        output_img2 = effb4(transformed_img2)\n",
    "        \n",
    "        combined_preds = torch.cat([output.unsqueeze(2), output_img1.unsqueeze(2), output_img2.unsqueeze(2)], dim=2)\n",
    "        \n",
    "        # 결합된 텐서에서 각 샘플에 대해 가장 높은 확률을 가진 클래스의 인덱스 찾기\n",
    "        # max 함수는 최대값과 해당 값의 인덱스를 반환합니다. 여기서는 인덱스만 필요합니다.\n",
    "        max_probs, max_indices = combined_preds.max(dim=2)\n",
    "        \n",
    "        # 최대 확률을 가진 인덱스 중 하나를 선택 (여기서는 가장 높은 확률의 인덱스를 사용)\n",
    "        final_preds = max_indices[torch.arange(max_indices.size(0)), max_probs.argmax(dim=1)]\n",
    "        \n",
    "    preds_list.extend(final_preds.cpu().numpy())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list\n",
    "sample_submission_df = pd.read_csv(submission_path)\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()\n",
    "pred_df.to_csv('./effb4-add_50000_3tta_argmax_Notdivide255.csv', index=False)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:37<00:00,  1.01it/s]\n"
     ]
    }
   ],
   "source": [
    "preds_list = []\n",
    "\n",
    "# Albumentations 변환 정의\n",
    "transform_tta = A.Compose([\n",
    "    A.Flip(p=1.0),  # 수평 뒤집기\n",
    "    A.Rotate(limit=279, p=0.5),  # 회전\n",
    "    A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.5),  # 선명하게\n",
    "\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "for images, labels in tqdm(test_dataloader):\n",
    "    images = images.float().to(device)\n",
    "    with torch.no_grad():\n",
    "        # 이미지 배치를 CPU로 이동시키고 NumPy 배열로 변환\n",
    "        images_np = images.cpu().numpy()\n",
    "        #print(images_np.shape)  32,3,380,380\n",
    "        # 변환된 이미지를 저장할 배열 초기화\n",
    "        transformed_imgs1 = []\n",
    "        transformed_imgs2 = []\n",
    "        \n",
    "        # 각 이미지에 대해 변환 적용\n",
    "        for img_np in images_np:\n",
    "            # 이미지 하나에 대해 변환 적용\n",
    "            # print(img_np.shape) 3,380,380\n",
    "            transformed_data1 = transform_tta(image=img_np)\n",
    "            transformed_data2 = transform_tta(image=img_np)\n",
    "            \n",
    "            # 변환된 이미지 배열에 추가\n",
    "            transformed_imgs1.append(transformed_data1['image'].permute(1,0,2))\n",
    "            transformed_imgs2.append(transformed_data2['image'].permute(1,0,2))\n",
    "            \n",
    "        \n",
    "        # NumPy 배열로 변환된 이미지들을 PyTorch 텐서로 변환\n",
    "        transformed_img1 = torch.tensor(np.array(transformed_imgs1), dtype=torch.float).to(device)\n",
    "        transformed_img2 = torch.tensor(np.array(transformed_imgs2), dtype=torch.float).to(device)\n",
    "        \n",
    "        # 모델 예측 수행\n",
    "        \n",
    "                \n",
    "        output = effb4(images)\n",
    "        output_img1 = effb4(transformed_img1)\n",
    "        output_img2 = effb4(transformed_img2)\n",
    "        \n",
    "        combined_preds = torch.cat([output.unsqueeze(2), output_img1.unsqueeze(2), output_img2.unsqueeze(2)], dim=2)\n",
    "        \n",
    "        # 결합된 텐서에서 각 샘플에 대해 가장 높은 확률을 가진 클래스의 인덱스 찾기\n",
    "        # max 함수는 최대값과 해당 값의 인덱스를 반환합니다. 여기서는 인덱스만 필요합니다.\n",
    "        max_probs, max_indices = combined_preds.max(dim=2)\n",
    "        \n",
    "        # 최대 확률을 가진 인덱스 중 하나를 선택 (여기서는 가장 높은 확률의 인덱스를 사용)\n",
    "        final_preds = max_indices[torch.arange(max_indices.size(0)), max_probs.argmax(dim=1)]\n",
    "        \n",
    "    preds_list.extend(final_preds.cpu().numpy())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008fdb22ddce0ce.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091bffdffd83de.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00396fbc1f6cc21d.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00471f8038d9c4b6.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00901f504008d884.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID  target\n",
       "0  0008fdb22ddce0ce.jpg       0\n",
       "1  00091bffdffd83de.jpg       0\n",
       "2  00396fbc1f6cc21d.jpg       0\n",
       "3  00471f8038d9c4b6.jpg       0\n",
       "4  00901f504008d884.jpg       0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list\n",
    "sample_submission_df = pd.read_csv(submission_path)\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()\n",
    "pred_df.to_csv('./effb4-add_50000_3tta_argmax_sharpenNotdivide255.csv', index=False)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:29<00:00,  3.37it/s]\n"
     ]
    }
   ],
   "source": [
    "preds_list = []\n",
    "\n",
    "for images, labels in tqdm(test_dataloader):\n",
    "    images = images.type(torch.cuda.FloatTensor)\n",
    "    images = images.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = effb4(images)\n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_df = pd.read_csv(submission_path)\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('./effb4-add_50000-double-check.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008fdb22ddce0ce.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091bffdffd83de.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00396fbc1f6cc21d.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00471f8038d9c4b6.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00901f504008d884.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID  target\n",
       "0  0008fdb22ddce0ce.jpg       2\n",
       "1  00091bffdffd83de.jpg      12\n",
       "2  00396fbc1f6cc21d.jpg       5\n",
       "3  00471f8038d9c4b6.jpg      12\n",
       "4  00901f504008d884.jpg       2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
