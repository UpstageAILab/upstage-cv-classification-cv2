{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms, utils, datasets, models\n",
    "from torch.nn.modules.loss import BCEWithLogitsLoss\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from time import time\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import wandb\n",
    "\n",
    "from augraphy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 데이터 추가 코드\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "def augment_data_and_update_csv(input_folder, output_folder, aug, alb, csv_file, csv_name, num_augmented_per_image=4):\n",
    "    # Load the original CSV file\n",
    "    original_df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Create a new DataFrame for augmented data\n",
    "    augmented_df = pd.DataFrame(columns=original_df.columns)\n",
    "\n",
    "    # Define augmentation pipeline\n",
    "    aug = aug # augraphy 변환\n",
    "\n",
    "    alb = alb # albumentation 변환\n",
    "    # Get a list of all image files in the input folder\n",
    "    image_files = glob(os.path.join(input_folder, '*.jpg'))\n",
    "\n",
    "    for img_path in image_files:\n",
    "        # Read the image\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        # Apply augmentation multiple times\n",
    "        for i in tqdm(range(num_augmented_per_image)):\n",
    "            augraphy = aug(img)\n",
    "            augmented = alb(image=augraphy)\n",
    "            augmented_img = augmented['image']\n",
    "\n",
    "            # Save augmented image\n",
    "            output_path = os.path.join(output_folder, f\"augmented_{i}_{os.path.basename(img_path)}\")\n",
    "            cv2.imwrite(output_path, augmented_img)\n",
    "\n",
    "            # Add entry to the augmented DataFrame\n",
    "            augmented_entry = {\n",
    "                'ID': os.path.basename(output_path),\n",
    "                'target': original_df[original_df['ID'] == os.path.basename(img_path)]['target'].values[0]\n",
    "            }\n",
    "            augmented_df = pd.concat([augmented_df, pd.DataFrame([augmented_entry])], ignore_index=True)\n",
    "\n",
    "    # Concatenate original and augmented DataFrames\n",
    "    combined_df = pd.concat([original_df, augmented_df], ignore_index=True)\n",
    "\n",
    "    # Save the new CSV file\n",
    "    combined_df.to_csv(os.path.join(output_folder, csv_name), index=False)\n",
    "\n",
    "input_folder = \"/data/ephemeral/home/upstage_cv/data/train\"\n",
    "#output_folder = \"/data/ephemeral/home/upstage_cv/data/aug_img/lmj\"\n",
    "original_csv_file = \"/data/ephemeral/home/upstage_cv/data/train.csv\"\n",
    "\n",
    "# augment_data_and_update_csv(input_folder, output_folder, original_csv_file, num_augmented_per_image=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_path = '/data/ephemeral/home/upstage_cv/data/meta.csv'\n",
    "train_path = '/data/ephemeral/home/upstage_cv/data/train.csv'\n",
    "submission_path = '/data/ephemeral/home/upstage_cv/data/sample_submission.csv'\n",
    "\n",
    "meta_data = pd.read_csv(meta_path)\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_submission = pd.read_csv(submission_path)\n",
    "\n",
    "merge = pd.merge(df_train, meta_data, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드를 고정합니다.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, album_transform=None, augraphy_transform=None):\n",
    "        self.df = pd.read_csv(csv).values\n",
    "        self.path = path \n",
    "        self.album_transform = album_transform\n",
    "        self.augraphy_transform = augraphy_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        \n",
    "        if self.augraphy_transform:\n",
    "            img = self.augraphy_transform(img)\n",
    "\n",
    "        if self.album_transform:\n",
    "            img = self.album_transform(image=img)['image']\n",
    "        \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, dataloader, dataset, device, criterion, optimizer, epoch, num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    tbar = tqdm(dataloader)\n",
    "    for images, labels in tbar:\n",
    "        images = images.type(torch.cuda.FloatTensor)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(outputs.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "        tbar.set_description(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss : {loss.item():.4f}\")\n",
    "\n",
    "    train_loss = train_loss / (len(dataloader))\n",
    "    train_acc = accuracy_score(preds_list, targets_list)\n",
    "    train_f1 = f1_score(preds_list, targets_list, average='macro')\n",
    "\n",
    "    metrics = {\n",
    "        'train_loss' : train_loss,\n",
    "        'train_acc' : train_acc,\n",
    "        'train_f1' : train_f1\n",
    "    }\n",
    "\n",
    "    return model, metrics\n",
    "\n",
    "def evaluation(model, dataloader, dataset, device, criterion, epoch, num_epochs):\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tbar = tqdm(dataloader)\n",
    "        for images, labels in tbar:\n",
    "            images = images.type(torch.cuda.FloatTensor)\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "            preds_list.extend(outputs.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "            tbar.set_description(f\"Epcoh [{epoch+1}/{num_epochs}] Valid Loss : {valid_loss:.4f}\")\n",
    "\n",
    "    valid_loss /= len(dataloader)\n",
    "    valid_acc = accuracy_score(preds_list, targets_list)\n",
    "    valid_f1 = f1_score(preds_list, targets_list, average='macro')\n",
    "\n",
    "    metrics = {\n",
    "        'valid_loss' : valid_loss,\n",
    "        'valid_acc' : valid_acc,\n",
    "        'valid_f1' : valid_f1\n",
    "    }\n",
    "\n",
    "    return model, metrics\n",
    "\n",
    "def training_loop(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, device, num_epochs, model_path, model_name, patience, run):\n",
    "\n",
    "    best_valid_loss = float('inf')\n",
    "    valid_max_accuracy = -1\n",
    "    valid_max_f1 = -1\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model, train_metrics = training(model, train_dataloader, train_dataset, device, criterion, optimizer, epoch, num_epochs)\n",
    "        model, valid_metrics = evaluation(model, valid_dataloader, valid_dataset, device, criterion, epoch, num_epochs)\n",
    "\n",
    "        monitoring_value = {\n",
    "            'train_loss' : train_metrics['train_loss'],\n",
    "            'train_accuracy' : train_metrics['train_acc'],\n",
    "            'train_f1' : train_metrics['train_f1'],\n",
    "            'valid_loss' : valid_metrics['valid_loss'],\n",
    "            'valid_accuracy' : valid_metrics['valid_acc'],\n",
    "            'valid_f1' : valid_metrics['valid_f1']\n",
    "        }\n",
    "        run.log(monitoring_value, step=epoch)\n",
    "\n",
    "        if valid_max_accuracy < valid_metrics['valid_acc']:\n",
    "            valid_max_accuracy = valid_metrics['valid_acc']\n",
    "\n",
    "            run.summary['best_train_acc'] = train_metrics['train_acc']\n",
    "            run.summary['best_valid_acc'] = valid_metrics['valid_acc']\n",
    "        \n",
    "        if valid_max_f1 < valid_metrics['valid_f1']:\n",
    "            valid_max_f1 = valid_metrics['valid_f1']\n",
    "            torch.save(model.state_dict(), model_path+f\"/model_{model_name}.pt\")\n",
    "\n",
    "            run.summary['best_train_f1'] = train_metrics['train_f1']\n",
    "            run.summary['best_valid_f1'] = valid_metrics['valid_f1']\n",
    "\n",
    "        if best_valid_loss > valid_metrics['valid_loss']:\n",
    "            best_valid_loss = valid_metrics['valid_loss']\n",
    "\n",
    "            run.summary['best_train_loss'] = train_metrics['train_loss']\n",
    "            run.summary['best_valid_loss'] = valid_metrics['valid_loss']\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss : {train_metrics['train_loss']:.4f}, Train Acc : {train_metrics['train_acc']:.4f}, 'Train F1 : {train_metrics['train_f1']:.4f}, Valid Loss : {valid_metrics['valid_loss']:.4f}, Valid Acc : {valid_metrics['valid_acc']:.4f}, Valid F1 : {valid_metrics['valid_f1']}\")\n",
    "\n",
    "        if early_stop_counter >= patience:\n",
    "            print('Early Stopping!')        \n",
    "            break\n",
    "\n",
    "    return model, valid_max_accuracy, valid_max_f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyper Parameter 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('resnet34', pretrained=True, num_classes=17)\n",
    "class Cfg():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    num_epochs = 100\n",
    "    batch_size = 32\n",
    "    model_path = '/data/ephemeral/home/upstage_cv/models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Experiment (num_augmented=8, p=0.6, epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"/data/ephemeral/home/upstage_cv/data/aug_img/sjy\"\n",
    "\n",
    "# augraphy\n",
    "ink_phase = [\n",
    "    Folding(p=0.6)\n",
    "    ]\n",
    "\n",
    "paper_phase = [\n",
    "    ColorPaper(p=0.6),\n",
    "    ColorShift(p=0.6),\n",
    "    ReflectedLight(p=0.6)\n",
    "]\n",
    "\n",
    "post_phase = [\n",
    "    VoronoiTessellation(p=0.6),\n",
    "]\n",
    "pipeline = AugraphyPipeline(ink_phase=ink_phase, paper_phase=paper_phase, post_phase=post_phase)\n",
    "\n",
    "aug_sjy = pipeline\n",
    "\n",
    "# albumentation\n",
    "alb_sjy = A.Compose([\n",
    "    A.HorizontalFlip(p=0.6),\n",
    "    A.VerticalFlip(p=0.6),\n",
    "    A.Rotate(p=0.6),\n",
    "    A.GaussianBlur(p=0.6),\n",
    "    A.RandomBrightnessContrast(p=0.6),\n",
    "    A.HueSaturationValue(p=0.6),\n",
    "    A.RandomGamma(p=0.6),\n",
    "    A.ColorJitter(p=0.6),\n",
    "    A.CoarseDropout(p=0.6),\n",
    "    A.GaussNoise(p=0.6),\n",
    "    A.Resize(224, 224),\n",
    "    #ToTensorV2()\n",
    "])\n",
    "\n",
    "csv_name = 'augmented_sjy.csv'\n",
    "augment_data_and_update_csv(input_folder, output_folder, aug_sjy, alb_sjy, original_csv_file, csv_name=csv_name, num_augmented_per_image=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원본이미지 파일 옮겨주는 작업 해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_sjy_path = '/data/ephemeral/home/upstage_cv/data/aug_img/sjy/augmented_sjy.csv'\n",
    "df_sjy = pd.read_csv(aug_sjy_path)\n",
    "df_sjy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sjy_img_path = '/data/ephemeral/home/upstage_cv/data/aug_img/sjy'\n",
    "test_img_path = '/data/ephemeral/home/upstage_cv/data/test/'\n",
    "totensor_transform = A.Compose([A.Resize(224, 224), ToTensorV2()])\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "train_dataset = ImageDataset(aug_sjy_path, sjy_img_path, album_transform=totensor_transform, augraphy_transform=None)\n",
    "test_dataset = ImageDataset(submission_path, test_img_path, album_transform=test_transform, augraphy_transform=None)\n",
    "\n",
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num, valid_num = int(len(train_dataset) * 0.8), int(len(train_dataset) * 0.2)\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [train_num, valid_num])\n",
    "\n",
    "print(len(train_dataset), len(valid_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=Cfg.batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=Cfg.batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=Cfg.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  run = wandb.init(project='AIStage-CV', name='resnet34-Aug-sjy')\n",
    "\n",
    "device = Cfg.device\n",
    "model = Cfg.model\n",
    "criterion = Cfg.criterion\n",
    "optimizer = Cfg.optimizer \n",
    "num_epochs = Cfg.num_epochs\n",
    "model_name = 'resnet34-aug-sjy'\n",
    "model_path = Cfg.model_path\n",
    "\n",
    "# run.watch(model, criterion, log='all', log_graph=True)\n",
    "\n",
    "model, valid_max_accuracy, valid_max_f1 = training_loop(model, train_dataloader, valid_dataloader, train_dataset, valid_dataset, criterion, optimizer, device, num_epochs, model_path, model_name, 20, run)\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lmj = timm.create_model('resnet34', pretrained=True, num_classes=17)\n",
    "model_lmj.load_state_dict(torch.load('/data/ephemeral/home/upstage_cv/models/model_resnet34-aug-lmj.pt'))\n",
    "model_lmj = model_lmj.to(device)\n",
    "model_lmj.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_list = []\n",
    "\n",
    "for images, labels in tqdm(test_dataloader):\n",
    "    images = images.type(torch.cuda.FloatTensor)\n",
    "    images = images.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model_lmj(images)\n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_df = pd.read_csv(submission_path)\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('resnet34-aug-lmj.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sjy = timm.create_model('resnet34', pretrained=True, num_classes=17)\n",
    "model_sjy.load_state_dict(torch.load('/data/ephemeral/home/upstage_cv/models/model_resnet34-aug-sjy.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sjy.to(device)\n",
    "preds_list = []\n",
    "\n",
    "for images, labels in tqdm(test_dataloader):\n",
    "    images = images.type(torch.cuda.FloatTensor)\n",
    "    images = images.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model_sjy(images)\n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(test_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_df = pd.read_csv(submission_path)\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('resnet34-aug-sjy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
